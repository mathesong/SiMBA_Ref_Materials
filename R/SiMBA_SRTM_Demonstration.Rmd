---
title: "SiMBA SRTM Demonstration"
always_allow_html: true
output:
  github_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
    toc_float:
      toc_collapsed: yes
---

# Aims

Here I aim to demonstrate the application of SiMBA and reference tissue models on a simulated dataset

# Preparation

## Libraries

First we load the required packages.

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
library(brms)
library(rstan)
library(cmdstanr)
library(furrr)
library(tictoc)
library(broom.mixed)

#remotes::install_github("mathesong/kinfitr")
library(kinfitr)

theme_set(theme_light())

set.seed(42)
```

## Data

The first step is to prepare your data so that it is ready for modelling. For SiMBA, the data needs to be in a long format, where there is a column for region and for time, and then a column for the time activity curve, or TAC, value in that region at that time point.  For *kinfitr* and SiMBA with reference tissue models, I would usually take this one step further and pull out the TAC for the reference region, and place it beside the TACs for all of the target regions.

The data ends up looking like this:

```{r}
rawdata <- readRDS("../RawData/rawdata.rds") 

rawdata
```

where *t_tac* represents the time, *dur* represents the duration of the frame, TAC represents the radioactivity in the target region, RefCBL represents the radioactivity in the reference region (in this case the cerebellum, CBL), and kfweights represents the *kinfitr* weights which were calculated in advance (and which are not necessary for fitting the data using SiMBA).

I've also included some true values for getting some insight into the simulations

```{r}
truedata <- readRDS("../RawData/truedata.rds")

truedata
```

Now, if we want to know what the true RefCBL TAC was at each time point, we can simply generate it by predicting from the model

```{r}
truedata <- truedata %>% 
  mutate(RefCBL_true = feng_1tc_tac_model(t_tac, t0_true, 
                                          A_true, B_true, C_true, 
                                          alpha_true, beta_true, gamma_true, 
                                          Ph1_true, Th1_true))
```



# Data Exploration

## Main Dataset

This data consists of simulated data from 10 controls, before and after treatment with a placebo intervention (true effect = 0); as well as 10 patients before and after treatment with a real intervention (true effect = +0.04 in logBPnd).  The patient group has a mean logBPnd of 0.08 less than the control group.

Each individual is defined by ID,, group membership is defined by Group, intervention is defined by Treatment, and each individual PET measurement is defined by PET.

```{r}
unique(rawdata$ID)

unique(rawdata$Group)

unique(rawdata$Treatment)

unique(rawdata$PET)
```


Looking at the a randomly selected PET measurement, let's visualise the measured TACs.

```{r}
dat_1 <- rawdata %>% 
  filter(PET == PET[sample(1:nrow(rawdata),1)])

ggplot(dat_1, aes(x=t_tac, y=TAC, colour=Region)) +
  geom_point() +
  geom_line(linewidth=0.1) +
  coord_cartesian(ylim=c(0,10))
```

Let's now compare these with their true values, as if these TACs were measured without any error, shown here with the lines.

```{r}
true_1 <- truedata %>% 
  filter(PET == dat_1$PET[1])
  

ggplot(dat_1, aes(x=t_tac, y=TAC, colour=Region)) +
  geom_point(aes(y=TAC)) +
  geom_line(data=true_1, linewidth=0.3, aes(y=TAC_true)) +
  coord_cartesian(ylim=c(0,10))
```

Lastly, we need to consider the reference region TAC from which these were generated, shown in black.

```{r}
ggplot(dat_1, aes(x=t_tac, y=TAC, colour=Region)) +
  geom_point(aes(y=TAC)) +
  geom_point(aes(y = RefCBL), colour="black") +
  geom_line(data=true_1, linewidth=0.3, aes(y=TAC_true)) +
  geom_line(data=true_1, aes(y = RefCBL_true), colour="black") +
  coord_cartesian(ylim=c(0,10))
```



# Modelling

## Conventional Fitting

First, I will demonstrate a conventional kinetic modelling procedure on the data using my package *kinfitr*.  First, we need to nest the data for each ROI.

```{r}
rawdata_nested <- rawdata %>% 
  group_by(ID, PET, Group, Treatment, Region) %>% 
  nest(.key="tacs")
```


The data then looks like this

```{r}
rawdata_nested
```

... and then the nested table called "tacs" for each measurement and region looks like this:

```{r}
rawdata_nested$tacs[[1]]
```


So, now we fit the SRTM model to each TAC, which are all nested within the nested tacs tables.

```{r, warning=FALSE, eval=FALSE}
rawdata_fits <- rawdata_nested %>% 
  group_by(ID, PET, Region) %>% 
  mutate(srtmfit = map(tacs, ~srtm(t_tac=.x$t_tac, reftac=.x$RefCBL, 
                                   roitac=.x$TAC, weights=.x$kfweights, 
                                   multstart_iter = 10)))

saveRDS(rawdata_fits, "../DerivedData/rawdata_srtmfits.rds")
```

In order to avoid having to re-fit the TACs, I've saved everything to the DerivedData folder, and we can load it from there.

```{r}
rawdata_fits <- readRDS("../DerivedData/rawdata_srtmfits.rds")
```


Let's see the fits from the first individual

```{r}
rawdata_fits %>% 
  ungroup() %>% 
  filter(PET == PET[1]) %>% 
  mutate(plot = map2(srtmfit, Region, ~plot(.x) + labs(title=.y))) %>% 
  pull(plot)
```


### Parameter Estimates

And let's plot the output parameters

```{r, fig.height=12, fig.width=6}
rawdata_pars <- rawdata_fits %>% 
  mutate(pars = map(srtmfit, "par")) %>% 
  select(ID:Region, pars) %>% 
  unnest(pars) %>% 
  pivot_longer(R1:bp, 
               names_to = "Parameter", 
               values_to = "Value") %>% 
  mutate(Parameter = fct_inorder(Parameter))

ggplot(rawdata_pars, aes(x=Value)) +
  geom_histogram(aes(fill=Region), bins = 20, colour="black") +
  facet_grid(Region~Parameter, scales="free")
```


### Inference

Now we can test the relevant contrasts. The true differences are as follows:

* Patients are simulated to be 0.08 log(BP~ND~) units below the controls.
* Placebo causes no change to the log(BP~ND~) value.
* Treatment causes an increase of 0.04 log(BP~ND~) units.

```{r}
bp_values <- rawdata_pars %>% 
  filter(Parameter=="bp") %>% 
  rename(bp = Value)

nls_mod <- lmer(log(bp) ~ Region + Group + Treatment + (1|ID), data=bp_values)

summary(nls_mod)
```

As we can see, the estimates of the relevant contrasts are quite close to the true values, however none of them are significant because of the wide standard errors.


## RefTAC Modelling

The way that SiMBA is designed, we need to fit the reference TAC prior to fitting SiMBA, and instead of using the reference TAC data, SiMBA simply uses the parametric representation of the reference TAC.  First I will extract the reference TACs: because it is the same for every region of each individual, I will first just filter for one region of each individual, and then use that.


```{r}
reftacs_nested <- rawdata_nested %>% 
  filter(Region=="FC") %>% 
  ungroup() %>% 
  select(-Region)

reftacs_nested
```


Then, for fitting it, I have included the fitting function within `kinfitr` for convenience, called `feng_1tc_tac`. Because this function has more parameters than are reasonable, because our intention is describing the TAC rather than learning about its true underlying parameters, it can quite easily land in local minima. For this reason, the function is defined so that the model fits each TAC a lot of times with randomly selected starting parameters. This reduces the likelihood of getting poor fits.  This can also be modified so that it's parallelised using the `furrr` package.


```{r, warning=FALSE, eval=FALSE}
cores = 2
plan(multisession, workers = cores)

reftacs_nested <- reftacs_nested %>% 
  mutate(reffit = future_map(tacs, ~kinfitr::feng_1tc_tac(t_tac = .x$t_tac, 
                                                          tac = .x$RefCBL, 
                                                          weights = .x$kfweights)))

saveRDS(reftacs_nested, "../DerivedData/reftacs_fitted.rds")
```

```{r}
reftacs_nested <- readRDS("../DerivedData/reftacs_fitted.rds")
```


Now let's examine our fits (I generally recommend giving them all a look-over to make sure that nothing went wrong).

```{r}
map(reftacs_nested$reffit[c(1,3,5,7,9)], plot)
```

These fits all look ok to me. Notably, the red line shows the fit, and the orange crosses show the points along the fits which correspond with the exact times of the data points. 

Note: you'll notice that occasionally the red lines go pretty high up: this is specific to this tracer. And at the end of the day, it's not a big deal: in the SRTM and FRTM function definitions, there's a convolution term (which will smooth out the deviation because of the integration), and there's an additive term, which could be more problematic.  But because the points at the times of the TAC time points (i.e. the orange crosses), are actually not so far out, that doesn't make too much of an impact either.

Then we can extract the estimated parameter values

```{r}
refpar <- reftacs_nested %>% 
  mutate(par = map(reffit, "par")) %>% 
  select(ID:Treatment, par) %>% 
  unnest(par)

refpar
```

Once we have our estimated parameters, we can join this to our TAC data ready for SiMBA modelling.

```{r}
rawdata_refpar <- rawdata %>% 
  inner_join(refpar)
```



## Reference Error Discussion

Now that we have our TACs, and our reftac parameter values, we can start to model the TACs themselves. With the simulated data, the fitted parameter values, as well as the true and fitted reference region TACs are already included, and we will use those.  Let's first visualise the first measurement's true (black) and fitted (red) reference region TAC.

```{r}
dat_1_fittedref <- rawdata_refpar %>% 
  filter(PET == dat_1$PET[1]) %>% 
  mutate(RefCBL_fitted = feng_1tc_tac_model(t_tac, t0, 
                                          A, B, C, 
                                          alpha, beta, gamma, 
                                          Ph1, Th1))

ggplot(true_1, aes(x=t_tac, y=RefCBL_true)) +
  geom_point() +
  geom_line(linewidth=0.1) +
  geom_point(data=dat_1_fittedref, aes(y=RefCBL_fitted), colour="red") +
  geom_line(data=dat_1_fittedref, aes(y=RefCBL_fitted), colour="red", linewidth=0.1)
```

As we can see, the fitted RefTAC is not exactly the same as the true RefTAC from which the TAC data are generated, but it's reasonably close.  This will always be a source of some variance.


## Nonlinear Least Squares (NLS) with a fitted reference region

The usual way that PET researchers model TACs is to fit each TAC individually and independently.  Usually, for fitting reference tissue models, we would simply interpolate the measurement reference region TAC, which is what happens in the *kinfitr* function above. However, with SiMBA, we will use the fitted reference region. This is much faster because the convolution can be solved analytically. For comparison purposes, we can also implement the same model with NLS.

```{r}
Feng_reftac_expconv <- function(time,
                                A, B, C, 
                                alpha, beta, gamma, 
                                Ph1, Th1, lambda) {
  
  (Ph1*((A*(-1 + exp((-alpha + lambda)*time)))/((alpha - lambda)*(alpha - Th1)^(2)) + 
          (alpha*A*(-1 + exp((-alpha + lambda)*time)*(1 + alpha*time - lambda*time)))/
          ((alpha - lambda)^(2)*(alpha - Th1)^(2)) + 
          (B*(-1 + exp((-alpha + lambda)*time)))/((-alpha + lambda)*(alpha - Th1)) +
          (C*(-1 + exp((-alpha + lambda)*time)))/((-alpha + lambda)*(alpha - Th1)) + 
          (B*(-1 + exp((-beta + lambda)*time)))/((beta - lambda)*(beta - Th1)) +
          (C*(-1 + exp((-gamma + lambda)*time)))/((gamma - lambda)*(gamma - Th1)) + 
          (A*(-1 + exp(time*(lambda - Th1))))/((alpha - Th1)^(2)*(lambda - Th1)) + 
          
          (A*(1 + exp((-alpha + lambda)*time)*(-1 - alpha*time + lambda*time))*Th1)/
          ((alpha - lambda)^(2)*(alpha - Th1)^(2)) + 
          (B*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-alpha + Th1)) +
          (C*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-alpha + Th1)) - 
          (B*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-beta + Th1)) - 
          (C*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-gamma + Th1))))/
    exp(lambda*time)
  
  
}

srtm_smoothana_model <- function(time, t0,
                                 A, B, C, 
                                 alpha, beta, gamma, 
                                 Ph1, Th1, 
                                 R1, k2prime, bp) {
  
  time <- time - t0
  
  k2 <- k2prime * R1
  
  a <- k2 - ((R1*k2) / (1+bp))
  b <- k2 / (1+bp)
  
  reftac = (time > 0) * (
    (Ph1*((B*(-1 + exp(time*(-alpha + Th1))))/(alpha - Th1) + 
            (C*(-1 + exp(time*(-alpha + Th1))))/(alpha - Th1) + 
            (B*(-1 + exp(time*(-beta + Th1))))/(-beta + Th1) + 
            (C*(-1 + exp(time*(-gamma + Th1))))/(-gamma + Th1) + 
            (A*(1 + exp(time*(-alpha + Th1))*(-1 - alpha*time + time*Th1)))/
            (alpha - Th1)^(2)))/exp(time*Th1)
  )
  
  (time > 0) * (
    # First term
    ( R1 * reftac ) + 
      
      # Second term
      ( a * Feng_reftac_expconv(time,
                                A, B, C, 
                                alpha, beta, gamma, 
                                Ph1, Th1, b) 
      )
  )
  
}
```


First, let's compare the time it takes to fit a single TAC using both approaches.

First, for the conventional approach, in which the reftac is interpolated and convolved using FFT

```{r}
dat_1_tac <- dat_1 %>% 
  filter(Region=="FC")

tic()
k <- srtm(dat_1_tac$t_tac, dat_1_tac$RefCBL, dat_1_tac$TAC, dat_1_tac$kfweights, 
           multstart_iter = 10,
           multstart_lower = list(R1=0.001, k2=0.001, bp=0.001),
           multstart_upper = list(R1=1.5, k2=0.5, bp=10))
toc()
```


```{r}
dat_1_tac <- left_join(dat_1_tac, rawdata_refpar)

tic()
k <- nls.multstart::nls_multstart(
      TAC ~ srtm_smoothana_model(t_tac, t0, A, B, C, alpha, beta, gamma, Ph1, Th1,
                                 R1, k2prime, bp),data = dat_1_tac, iter = 10,
      start_lower = c(R1=0.001, k2prime=0.001, bp=0.001),
      start_upper = c(R1=1.5, k2prime=0.5, bp=10),
      lower = c(R1=0.001, k2prime=0.001, bp=0.001),
      upper = c(R1=1.5, k2prime=0.5, bp=10),
      modelweights = kfweights, supp_errors = "N")
toc()
```

So using the analytical convolution, it's about 3 times faster.


Now, let's run it for all of the TACs.  First we nest the data by each TAC...

```{r}
rawdata_nested <- rawdata_refpar %>% 
  group_by(ID, Group, Treatment, PET, Region) %>% 
  nest()

rawdata_nested
```

... and fit the model

```{r}
rawdata_anafits <- rawdata_nested %>% 
  mutate(fit = map(data, ~nls.multstart::nls_multstart(
      TAC ~ srtm_smoothana_model(t_tac, t0, A, B, C, alpha, beta, gamma, Ph1, Th1,
                                 R1, k2prime, bp),data = .x, iter = 10,
      start_lower = c(R1=0.001, k2prime=0.001, bp=0.001),
      start_upper = c(R1=1.5, k2prime=0.5, bp=10),
      lower = c(R1=0.001, k2prime=0.001, bp=0.001),
      upper = c(R1=1.5, k2prime=0.5, bp=10),
      modelweights = kfweights, supp_errors = "N")))

rawdata_anapars <- rawdata_anafits %>% 
  ungroup() %>% 
  mutate(pars = map(fit, ~as_tibble(as.list(coef(.x))))) %>% 
  select(-fit) %>% 
  unnest(pars) %>% 
  mutate(logR1 = log(R1),
         logk2prime = log(k2prime),
         logBPnd = log(bp))
```

### Parameter Estimates

We can compare these parameters with those we calculated before using the interpolated reference TACs.  I will also just convert the k2prime into k2 values for comparison, which is equal to R1*k2prime.

```{r}
rawdata_anapars_long <- rawdata_anapars %>% 
  select(-data) %>% 
  mutate(k2 = R1*k2prime) %>% 
  select(-starts_with("log")) %>% 
  pivot_longer(c(R1, k2, bp, k2prime), names_to = "Parameter", values_to = "ana_Values")
```


Now we can compare with the interpolated values

```{r, fig.height=15, fig.width=6}
rawdata_pars %>% 
  inner_join(rawdata_anapars_long) %>% 
  group_by(Region, Parameter) %>% 
  summarise(cor = cor(Value, ana_Values))

rawdata_pars %>% 
  inner_join(rawdata_anapars_long) %>% 
  ggplot(aes(x=Value, y=ana_Values)) +
  geom_point() +
  facet_wrap(Region~Parameter, scales="free", ncol=3) +
  geom_abline(slope=1,intercept=0, linetype="dashed") +
  labs(x="NLS (kinfitr)", y="NLS (Analytical Convolution)")
```

As we can see, they are very similar.


Let's also compare our fitted parameters with the true parameters.

```{r}
rawdata_anaconv_truepars <- truedata %>% 
  filter(!duplicated(paste(ID, PET, Group, Treatment, Region))) %>% 
  select(ID:Region, logR1_true, logk2prime_true, logBPnd_true) %>% 
  mutate(R1 = exp(logR1_true),
         k2prime = exp(logk2prime_true),
         bp = exp(logBPnd_true)) %>% 
  select(-starts_with("log")) %>% 
  pivot_longer(R1:bp, values_to = "true_Values", names_to = "Parameter")
```

```{r, fig.height=15, fig.width=6}
rawdata_anaconv_truepars %>% 
  inner_join(rawdata_anapars_long) %>% 
  ggplot(aes(x=true_Values, y=ana_Values)) +
  geom_point() +
  facet_wrap(Region~Parameter, scales="free", ncol=3) +
  geom_abline(slope=1,intercept=0, linetype="dashed")
```

Still looks to be doing a pretty ok job!


### Inference

Now, we can evaluate group differences and treatment effects using a mixed linear model.


```{r}
nls_anaconv_mod <- lmer(logBPnd ~ 1 + Region + Group + Treatment + (1 | ID),
                          data=rawdata_anapars)

summary(nls_anaconv_mod)
```

Once again, we're quite close to the correct parameter values, but the comparisons are not significant because the standard error is too wide.


## SiMBA

Now, for our SiMBA model, we must first define our specific predictors and our priors. First, we define one region as the comparison region for the fixed effects. We will use the frontal cortex for this purpose.

```{r}
modeldat <- rawdata_refpar %>% 
  mutate(Region = as.factor(Region),
         Region = relevel(Region, "FC"))
```


Then we need to define the pharmacokinetic model definition in STAN code. I've included both the SRTM and FRTM here, but we will use the SRTM.

```{r}
rtm_stan = "
real Feng_reftac_expconv(real time, real A, real B, real C, 
                       real alpha, real beta, real gamma, 
                       real Ph1, real Th1, real lambda) {
     
    real out;
    
    out = (Ph1*((A*(-1 + exp((-alpha + lambda)*time)))/((alpha - lambda)*(alpha - Th1)^(2)) + 
          (alpha*A*(-1 + exp((-alpha + lambda)*time)*(1 + alpha*time - lambda*time)))/
          ((alpha - lambda)^(2)*(alpha - Th1)^(2)) + 
          (B*(-1 + exp((-alpha + lambda)*time)))/((-alpha + lambda)*(alpha - Th1)) +
          (C*(-1 + exp((-alpha + lambda)*time)))/((-alpha + lambda)*(alpha - Th1)) + 
          (B*(-1 + exp((-beta + lambda)*time)))/((beta - lambda)*(beta - Th1)) +
          (C*(-1 + exp((-gamma + lambda)*time)))/((gamma - lambda)*(gamma - Th1)) + 
          (A*(-1 + exp(time*(lambda - Th1))))/((alpha - Th1)^(2)*(lambda - Th1)) + 
          
          (A*(1 + exp((-alpha + lambda)*time)*(-1 - alpha*time + lambda*time))*Th1)/
          ((alpha - lambda)^(2)*(alpha - Th1)^(2)) + 
          (B*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-alpha + Th1)) +
          (C*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-alpha + Th1)) - 
          (B*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-beta + Th1)) - 
          (C*(-1 + exp(time*(lambda - Th1))))/((lambda - Th1)*(-gamma + Th1))))/
    exp(lambda*time);
   
   return(out);
                       
}
real frtm_model(real logR1, real logk2prime, 
                    real logBPnd, real logk4,
                    real time, real t0,
                    real A, real B, real C, 
                    real alpha, real beta, real gamma, 
                    real Ph1, real Th1) {
  
  real R1;
  real k2prime;
  real BPnd;
  real k4;
  
  real k2;
  real k3;
  real s;
  real r;
  real q;
  real p;
  real d;
  real c;
  real b;
  real a;
  
  real pred;
  
  real reftac;
  real tcorr;
  
  R1 = exp(logR1);
  k2prime = exp(logk2prime);
  BPnd = exp(logBPnd);
  k4 = exp(logk4);
  
  k2 = k2prime * R1;
  k3 = BPnd * k4;
  s = k2 + k3 + k4;
  r = k2/R1;
  q = 4 * k2 * k4;
  p = sqrt(s^2 - q);
  d = (s - p)/2;
  c = (s + p)/2;
  b = (d - k3 - k4) * (d - r)/p;
  a = (k3 + k4 - c) * (c - r)/p;
  
  tcorr = time - t0;
  
  reftac = (tcorr > 0) * (
    (Ph1*((B*(-1 + exp(tcorr*(-alpha + Th1))))/(alpha - Th1) + 
              (C*(-1 + exp(tcorr*(-alpha + Th1))))/(alpha - Th1) + 
              (B*(-1 + exp(tcorr*(-beta + Th1))))/(-beta + Th1) + 
              (C*(-1 + exp(tcorr*(-gamma + Th1))))/(-gamma + Th1) + 
              (A*(1 + exp(tcorr*(-alpha + Th1))*(-1 - alpha*tcorr + tcorr*Th1)))/
              (alpha - Th1)^(2)))/exp(tcorr*Th1)
              );
  
  pred = R1 * (
    reftac + 
    a * Feng_reftac_expconv(tcorr,
                          A, B, C, 
                          alpha, beta, gamma, 
                          Ph1, Th1, c) +
    (tcorr > 0) * b * Feng_reftac_expconv(tcorr,
                              A, B, C, 
                              alpha, beta, gamma, 
                              Ph1, Th1, d)
       );
       
  return(pred);
  
}

real srtm_model(real logR1, real logk2prime, real logBPnd,
                    real time, real t0,
                    real A, real B, real C, 
                    real alpha, real beta, real gamma, 
                    real Ph1, real Th1) {
  
  real R1;
  real k2prime;
  real BPnd;
  real k2;
  
  real a;
  real b;
  
  real pred;
  
  real reftac;
  real tcorr;
  
  R1 = exp(logR1);
  k2prime = exp(logk2prime);
  BPnd = exp(logBPnd);
  k2 = k2prime * R1;
  
  tcorr = time - t0;
  
  reftac = (tcorr > 0) * (
    (Ph1*((B*(-1 + exp(tcorr*(-alpha + Th1))))/(alpha - Th1) + 
              (C*(-1 + exp(tcorr*(-alpha + Th1))))/(alpha - Th1) + 
              (B*(-1 + exp(tcorr*(-beta + Th1))))/(-beta + Th1) + 
              (C*(-1 + exp(tcorr*(-gamma + Th1))))/(-gamma + Th1) + 
              (A*(1 + exp(tcorr*(-alpha + Th1))*(-1 - alpha*tcorr + tcorr*Th1)))/
              (alpha - Th1)^(2)))/exp(tcorr*Th1)
              );
  
  a = k2 - ((R1*k2) / (1+BPnd));
  b = k2 / (1+BPnd);
  
  // First term
  pred = ( R1 * reftac ) + 
    
  // Second term
  (tcorr > 0) * ( a * Feng_reftac_expconv(tcorr,
                            A, B, C, 
                            alpha, beta, gamma, 
                            Ph1, Th1, b));
       
  return(pred);
  
}
"
```


## Testing the Function with a single TAC

First, let's apply the function to fit a single TAC, but fit using MCMC.

Firstly, we need to convert the weights into multipliers for sigma, and then centre them.

```{r}
dat_1_tac <- dat_1_tac %>% 
  mutate(sqrtinvkfw = sqrt(1/kfweights),
         sqrtinvkfw = sqrtinvkfw / mean(sqrtinvkfw))
```

Now we can fit the model using MCMC with `brms`

```{r}
srtm_prior <- c(
  set_prior("normal(0, 0.5)", nlpar = "logR1"),
  set_prior("normal(-2, 0.5)", nlpar = "logk2prime"),
  set_prior("normal(0.5, 0.5)", nlpar = "logBPnd"),
  
  set_prior("normal(-0.5, 1)", dpar = "sigma", coef="sqrtinvkfw"))


srtm_fit_formula <- bf( TAC ~ srtm_model(logR1, logk2prime, logBPnd, 
                                              t_tac, t0,
                                              A, B, C,
                                              alpha, beta, gamma,
                                              Ph1, Th1),
     sigma ~ 0 + sqrtinvkfw,
     # Nonlinear variables
     logR1 + logk2prime + logBPnd ~ 1,
     # Nonlinear fit
     nl = TRUE)

get_prior(srtm_fit_formula, data=dat_1_tac, family = gaussian())

# make_stancode(srtm_fit_formula,
#   family=gaussian(), 
#   data = dat_1_tac,
#   prior = srtm_prior,
#   stanvars = stanvar(scode = rtm_stan, 
#                      block="functions"))


srtm_fit <- brm(
  srtm_fit_formula,
  family=gaussian(),
  data = dat_1_tac,
  prior = srtm_prior,
  stanvars = stanvar(scode = rtm_stan,
             block="functions"),
  control = list(adapt_delta=0.90),
  chains = 3,
  cores = 3,
  iter = 2000,
  backend = "rstan", init = 0)

  

summary(srtm_fit)


```

And then let's plot the results

```{r}
brms::expose_functions(srtm_fit, vectorize=TRUE)

pred <- predict(srtm_fit) %>% 
  as_tibble() %>% 
  select(P_L95 = "Q2.5",
         P_U95 = "Q97.5")

fitted <- fitted(srtm_fit) %>% 
  as_tibble() %>% 
  select(Estimate, 
         F_L95 = "Q2.5",
         F_U95 = "Q97.5")

dat_1_fitted <- dat_1_tac %>% 
  bind_cols(pred) %>% 
  bind_cols(fitted)

ggplot(dat_1_fitted, aes(x=t_tac, y=TAC)) +
  geom_point() +
  geom_ribbon(aes(ymin=P_L95, ymax=P_U95), alpha=0.1) +
  geom_ribbon(aes(ymin=F_L95, ymax=F_U95), alpha=0.2) +
  geom_line(aes(y=Estimate)) +
  labs(title = "SRTM Model Fit")


```



## Fitting the SiMBA model


Next, we define our predictors.  For sigma, we have a couple of extra parameters: we include the centred natural logarithm duration of each frame. We also have a region size, which we have also taken the natural logarithm of, and then centred around zero. For this exercise, I will simply increase the SD of the random effects for region and estimate the regional differences in the measurement error.

```{r}
modeldat <- modeldat %>% 
  mutate(dur_logc = log(dur) - mean(log(dur)))

simbasrtm_fit_formula <- bf( TAC ~ srtm_model(logR1, logk2prime, logBPnd,
                                           t_tac, t0,
                                           A, B, C,
                                           alpha, beta, gamma,
                                           Ph1, Th1),
                          lf(sigma ~ 1 + s(t_tac) + 
                               dur_logc + 
                               (1 | Region) + (1 | PET), center = FALSE),
                          # Nonlinear variables
                          logR1 ~ 1 + Region + (1|k|ID) + 
                            (1|l|PET:Region),
                          logk2prime ~ 1 + (1|m|Region) + (1|k|ID) +
                            (1|l|PET:Region),
                          logBPnd ~ 1 + Region + Group + Treatment + 
                            (1|k|ID) + (1|l|PET:Region),
                          # Nonlinear fit
                          nl = TRUE, center = TRUE)
```

Now we define the prior.  I have commented out the injected radioactivity, which I would usually include for real data.

```{r}
simbasrtm_prior <- c(
  
  set_prior("normal(0, 0.25)", nlpar = "logR1"),
  set_prior("normal(-2, 0.25)", nlpar = "logk2prime"),
  set_prior("normal(0, 0.25)", nlpar = "logBPnd"),
  
  set_prior("normal(0, 0.3)", nlpar = "logR1", class = "sd", group="ID"),
  set_prior("normal(0, 0.1)", nlpar = "logk2prime", class = "sd", group="ID"),
  set_prior("normal(0, 0.3)", nlpar = "logBPnd", class = "sd", group="ID"),
  
  set_prior("normal(0, 0.025)", nlpar = "logR1", class = "sd", group="PET:Region"),
  set_prior("normal(0, 0.025)", nlpar = "logk2prime", class = "sd", group="PET:Region"),
  set_prior("normal(0, 0.025)", nlpar = "logBPnd", class = "sd", group="PET:Region"),
  
  set_prior("normal(0, 0.1)", nlpar = "logk2prime", class = "sd", group="Region"),
  
  set_prior("normal(0, 0.3)", coef="RegionACC",     nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionAMG",     nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionDBS",     nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionHIP",     nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionINS",     nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionOC",      nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionTHA",     nlpar="logR1"),
  set_prior("normal(0, 0.3)", coef="RegionVSTR",    nlpar="logR1"),
  
  set_prior("normal(0, 0.3)", coef="RegionACC",     nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionAMG",     nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionDBS",     nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionHIP",     nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionINS",     nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionOC",      nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionTHA",     nlpar="logBPnd"),
  set_prior("normal(0, 0.3)", coef="RegionVSTR",    nlpar="logBPnd"),
  
  set_prior("normal(0, 0.1)", coef="GroupPatient",   nlpar="logBPnd"),
  set_prior("normal(0, 0.1)", coef="TreatmentTreatment",   nlpar="logBPnd"),
  set_prior("normal(0, 0.1)", coef="TreatmentPlacebo",   nlpar="logBPnd"),
  
  set_prior("normal(-0.5, 1)", dpar = "sigma"),
  set_prior("normal(0, 0.3)", dpar = "sigma", class="sd", group="PET"),
  # set_prior("normal(0, 0.1)", dpar = "sigma", class="sd", group="Region"),
  # Here we widen the prior for the SD by region to accommodate not having region sizes
  set_prior("normal(0, 0.3)", dpar = "sigma", class="sd", group="Region"),
  
  set_prior("normal(0, 0.5)", coef="dur_logc", dpar = "sigma", class="b"),
  
  set_prior("student_t(3, 0, 4)", coef="st_tac_1", dpar = "sigma", class="b"),
  set_prior("student_t(3, 0, 2.5)", dpar = "sigma", class="sds"),
  
  set_prior("lkj(1)", class="cor", group = "ID"),
  set_prior("lkj(2)", class="cor", group = "PET:Region"))
```

And now we can fit the model. We could either simply run `brms`. But sometimes, we might prefer to generate the STAN code and STAN data to fit the model directly. This can be done as follows, and then we could feed that into `rstan` or `cmdstanr`

```{r}
sc <- make_stancode(simbasrtm_fit_formula,
                    family=gaussian(),
                    data = modeldat,
                    prior = simbasrtm_prior,
                    stanvars = stanvar(scode = rtm_stan,
                                       block="functions"))

stand <- brms::make_standata(simbasrtm_fit_formula, 
                             data = modeldat, 
                             family=gaussian(), 
                             prior = simbasrtm_prior)

stand_list <- list()
for (t in names(stand)) {
  stand_list[[t]] <- stand[[t]]
}
```

However, here I will just use `brms` directly here.

```{r, eval=FALSE}
simba_fit <- brms::brm(
    simbasrtm_fit_formula,
    family=gaussian(),
                    data = modeldat,
                    prior = simbasrtm_prior,
                    stanvars = stanvar(scode = rtm_stan,
                                       block="functions"),
    init = 0, iter = 1000, warmup = 300,
    chains=3, cores=3, seed = 753273)

saveRDS(simba_fit, "../DerivedData/simba_fit.rds")
```


# Evaluating the Model

One of the advantages of `brms` is that it gives us a lot of tools for evaluating the model fit, and a very readable model summary object.


```{r}
simba_fit <- readRDS("../DerivedData/simba_fit.rds")
print(simba_fit, digits=3)
```

## Inferences

Here we can see that, of the clinical inferences, the model has produced estimates which are very close to those of the LME models earlier.  However, the standard error of these estimates is reduced in comparison.  To demonstrate this, let's examine a plot of the estimates.

First I'll extract the estimates for the clinical covariates.

```{r}
nls_kinfitr_model <- nls_mod
nls_anaconv_model <- nls_anaconv_mod

nls_kinfitr_estimates <- broom.mixed::tidy(nls_kinfitr_model) %>% 
  select(Parameter = term, Estimate = estimate, Est.Error = std.error) %>% 
  mutate(`Q2.5` = Estimate + qnorm(0.025)*Est.Error,
         `Q10` = Estimate + qnorm(0.1)*Est.Error,
         `Q90` = Estimate + qnorm(0.1, lower.tail = F)*Est.Error,
         `Q97.5` = Estimate + qnorm(0.025, lower.tail = F)*Est.Error) %>% 
  filter(str_detect(Parameter, "Group|Treatment")) %>% 
  mutate(Method = "NLS (kinfitr) + LME") %>% 
  mutate(Dodge = 0.3)

nls_anaconv_estimates <- broom.mixed::tidy(nls_anaconv_model) %>% 
  select(Parameter = term, Estimate = estimate, Est.Error = std.error) %>% 
  mutate(`Q2.5` = Estimate + qnorm(0.025)*Est.Error,
         `Q10` = Estimate + qnorm(0.1)*Est.Error,
         `Q90` = Estimate + qnorm(0.1, lower.tail = F)*Est.Error,
         `Q97.5` = Estimate + qnorm(0.025, lower.tail = F)*Est.Error) %>% 
  filter(str_detect(Parameter, "Group|Treatment")) %>% 
  mutate(Method = "NLS (anaconv) + LME") %>% 
  mutate(Dodge = 0.0)
  

simba_estimates <- fixef(simba_fit, probs = c(0.025, 0.1, 0.9, 0.975)) %>% 
  as_tibble(rownames="Parameter") %>% 
  filter(str_detect(Parameter, "Group|Treatment")) %>% 
  mutate(Parameter = str_remove(Parameter, "logBPnd_")) %>% 
  mutate(Method = "SiMBA") %>% 
  mutate(Dodge = -0.3)
```

... and then we'll plot them.  I've left out the treatment - placebo here for convenience as it takes a little bit more code to extract from both the LME and SiMBA models (but do feel free to get in touch if you need help with this).

```{r, fig.height=5, fig.width=5}
clinical_plotdata <- bind_rows(nls_kinfitr_estimates, nls_anaconv_estimates,
                               simba_estimates) %>% 
  mutate(True = case_when(
    Parameter == "GroupPatient"       ~ -0.08,
    Parameter == "TreatmentPlacebo"   ~ 0,
    Parameter == "TreatmentTreatment" ~ 0.04,
  )) %>% 
  mutate(Parameter = case_when(
    Parameter == "GroupPatient"       ~ "Patient - Control",
    Parameter == "TreatmentPlacebo"   ~ "Placebo - Baseline",
    Parameter == "TreatmentTreatment" ~ "Treatment - Baseline")) %>% 
  mutate(Method = fct_inorder(Method))

ggplot(clinical_plotdata, aes(x=Estimate, y=Parameter, colour=Method)) +
  facet_wrap(~Parameter, nrow=3, scales="free") +
  expand_limits(x=0) +
  geom_errorbarh(aes(xmin=`Q2.5`, xmax=`Q97.5`), linewidth=0.5, height = 0,
                 position = position_nudge(y = clinical_plotdata$Dodge)) +
  geom_errorbarh(aes(xmin=`Q10`, xmax=`Q90`), linewidth=1, height = 0,
                 position = position_nudge(y = clinical_plotdata$Dodge)) +
  geom_point(position = position_nudge(y = clinical_plotdata$Dodge),
             size=2.5, colour="black") +
  geom_point(position = position_nudge(y = clinical_plotdata$Dodge),
             size=2) +
  geom_vline(aes(xintercept=True), linetype="dashed") +
  scale_color_brewer(type = "qual", palette = 2) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(title="Clinical Comparisons")
```

We can see in for all comparisons, even though the estimates of SiMBA and NLS are broadly similar, the error bars (credible) intervals of the SiMBA estimates are more narrow than for the NLS + LME estimates.  Below I've plotted the standard error (SE) of all models to emphasise this.

```{r, fig.height=5, fig.width=5}
ggplot(clinical_plotdata, aes(x=Est.Error, y=Parameter, colour=Method)) +
  facet_wrap(~Parameter, nrow=3, scales="free") +
  geom_point(position = position_nudge(y = clinical_plotdata$Dodge),
             size=2.5, colour="black") +
  geom_point(position = position_nudge(y = clinical_plotdata$Dodge),
             size=2) +
  expand_limits(x=0) +
  scale_color_brewer(type = "qual", palette = 2) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  geom_vline(xintercept = 0, linetype="dashed") +
  labs(title="SE of Clinical Comparisons")
```

## Parameter Estimates

We can also extract the parameter estimates and compare them with the true values.

```{r}
modelmat_TAC <- simba_fit$data %>% 
  as_tibble() %>% 
  group_by(PET, Region) %>% 
  dplyr::slice(1) %>% 
  ungroup()

extract_tac_parameter_estimates <- function(fit, parameter, modelmat) {
  
  vals <- posterior_epred(fit, 
                  newdata=modelmat %>% as.data.frame(), 
                  re_formula = ~ 1 + (1|ID) + (1|Region) + (1|PET:Region), 
                  nlpar = parameter) %>% 
  as_tibble() %>%
  gather(`PET:Region_n`, Value) %>% 
  group_by(`PET:Region_n`) %>% 
  summarise(Estimate = exp(mean(Value)), # Exponentiate them at the sample level to get estimates
            SE = sd(Value),
            Q2.5 = exp(quantile(Value, 0.025)), 
            Q97.5 = exp(quantile(Value, 0.975))) %>% 
  mutate(`PET:Region_n` = str_remove(`PET:Region_n`, "V"),
         `PET:Region_n` = as.numeric(`PET:Region_n`)) %>% 
  arrange(`PET:Region_n`) %>% 
  mutate(`PET:Region` = modelmat$`PET:Region`) %>% 
  left_join(modelmat)
  
  return(vals)
  
}


simba_estimates <- tibble(
  Parameter = c("logR1",
                "logk2prime",
                "logBPnd")) %>% 
  mutate(Estimates = map(Parameter, ~extract_tac_parameter_estimates(simba_fit, .x,
                                                                     modelmat_TAC))) %>% 
  unnest(Estimates) %>% 
  mutate(Region = str_match(`PET:Region`, "_([A-Z]*$)")[,2],
         ID = str_match(`PET:Region`, "^(\\w*_\\d*)_")[,2],
         PET = str_match(`PET:Region`, "^(\\w*)_[A-Z]*$")[,2]) %>% 
  mutate(Parameter = str_remove(Parameter, "log")) %>% 
  select(ID, PET, Group, Treatment, Region, 
         Parameter, SiMBA_Estimate = Estimate)
```

And let's compare them with the true values and the anaconv values

```{r}
parcompare <- rawdata_anaconv_truepars %>% 
  inner_join(rawdata_anapars_long) %>% 
  mutate(Parameter = ifelse(Parameter=="bp", "BPnd", Parameter)) %>% 
  inner_join(simba_estimates)
```


First, comparing the SiMBA estimates to those of NLS using the analytical convolution

```{r, fig.height=15, fig.width=6}
ggplot(parcompare, aes(x=ana_Values, y=SiMBA_Estimate)) +
  geom_point() +
  facet_wrap(Region~Parameter, scales="free", ncol=3) +
  geom_abline(slope=1,intercept=0, linetype="dashed") +
  labs(x="NLS (Analytical Convolution)", y="SiMBA")
```
Then comparing the SiMBA estimates to  the true values

```{r, fig.height=15, fig.width=6}
ggplot(parcompare, aes(x=true_Values, y=SiMBA_Estimate)) +
  geom_point() +
  facet_wrap(Region~Parameter, scales="free", ncol=3) +
  geom_abline(slope=1,intercept=0, linetype="dashed") +
  labs(x="True Values", y="SiMBA")
```

And finally, let's compare the correlations between the true values and the model estimates for each parameter in each region

```{r}
parcompare %>% 
  filter(Parameter=="R1") %>% 
  group_by(Region) %>% 
  summarise(
    `NLS Correlation` = cor(true_Values, ana_Values),
    `SiMBA Correlation` = cor(true_Values, SiMBA_Estimate)) %>% 
  knitr::kable(caption = "R1", digits=3)

parcompare %>% 
  filter(Parameter=="k2prime") %>% 
  group_by(Region) %>% 
  summarise(
    `NLS Correlation` = cor(true_Values, ana_Values),
    `SiMBA Correlation` = cor(true_Values, SiMBA_Estimate)) %>% 
  knitr::kable(caption = "k2prime", digits=3)

parcompare %>% 
  filter(Parameter=="BPnd") %>% 
  group_by(Region) %>% 
  summarise(
    `NLS Correlation` = cor(true_Values, ana_Values),
    `SiMBA Correlation` = cor(true_Values, SiMBA_Estimate)) %>% 
  knitr::kable(caption = "BPnd", digits=3)
```



